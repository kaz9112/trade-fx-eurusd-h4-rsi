{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Load the backtested trading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryPrice</th>\n",
       "      <th>win_loss</th>\n",
       "      <th>long_short</th>\n",
       "      <th>entry_month</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_day</th>\n",
       "      <th>entry_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3566</td>\n",
       "      <td>loss</td>\n",
       "      <td>short</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3566</td>\n",
       "      <td>loss</td>\n",
       "      <td>short</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3568</td>\n",
       "      <td>loss</td>\n",
       "      <td>short</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3568</td>\n",
       "      <td>loss</td>\n",
       "      <td>short</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3568</td>\n",
       "      <td>loss</td>\n",
       "      <td>short</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EntryPrice win_loss long_short  entry_month  entry_date  entry_day  \\\n",
       "0      1.3566     loss      short            4          23          0   \n",
       "1      1.3566     loss      short            4          23          0   \n",
       "2      1.3568     loss      short            4          24          1   \n",
       "3      1.3568     loss      short            4          24          1   \n",
       "4      1.3568     loss      short            4          24          1   \n",
       "\n",
       "   entry_hour  \n",
       "0           8  \n",
       "1           8  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "raw_data = pd.read_csv('trades_data.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryPrice</th>\n",
       "      <th>entry_month</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_day</th>\n",
       "      <th>entry_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.259341</td>\n",
       "      <td>6.767090</td>\n",
       "      <td>15.620958</td>\n",
       "      <td>2.109701</td>\n",
       "      <td>10.167826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.131127</td>\n",
       "      <td>3.453237</td>\n",
       "      <td>8.706682</td>\n",
       "      <td>1.635073</td>\n",
       "      <td>5.874165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.039650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.133285</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.256750</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.359370</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.592810</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EntryPrice  entry_month   entry_date    entry_day   entry_hour\n",
       "count  2443.000000  2443.000000  2443.000000  2443.000000  2443.000000\n",
       "mean      1.259341     6.767090    15.620958     2.109701    10.167826\n",
       "std       0.131127     3.453237     8.706682     1.635073     5.874165\n",
       "min       1.039650     1.000000     1.000000     0.000000     0.000000\n",
       "25%       1.133285     4.000000     8.000000     1.000000     8.000000\n",
       "50%       1.256750     7.000000    15.000000     2.000000    12.000000\n",
       "75%       1.359370    10.000000    23.000000     3.000000    16.000000\n",
       "max       1.592810    12.000000    31.000000     6.000000    20.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data decription\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.I. define dataframe for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define how many inferences we want to generate\n",
    "inf_count =  round(raw_data.shape[0]*0.05)\n",
    "inf_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryPrice</th>\n",
       "      <th>win_loss</th>\n",
       "      <th>long_short</th>\n",
       "      <th>entry_month</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_day</th>\n",
       "      <th>entry_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>1.22396</td>\n",
       "      <td>win</td>\n",
       "      <td>short</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>1.12940</td>\n",
       "      <td>win</td>\n",
       "      <td>short</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1.33881</td>\n",
       "      <td>loss</td>\n",
       "      <td>long</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>1.12722</td>\n",
       "      <td>win</td>\n",
       "      <td>short</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>1.12803</td>\n",
       "      <td>loss</td>\n",
       "      <td>short</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EntryPrice win_loss long_short  entry_month  entry_date  entry_day  \\\n",
       "2279     1.22396      win      short            1           3          6   \n",
       "1428     1.12940      win      short            9          16          2   \n",
       "1253     1.33881     loss       long            8          11          0   \n",
       "2187     1.12722      win      short            6          16          1   \n",
       "2423     1.12803     loss      short           12           6          0   \n",
       "\n",
       "      entry_hour  \n",
       "2279          12  \n",
       "1428           8  \n",
       "1253           8  \n",
       "2187          12  \n",
       "2423           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Data for model inference\n",
    "data_inf = raw_data.sample(inf_count, random_state=33)\n",
    "data_inf.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.II. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the raw_data\n",
    "raw_data_1 = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features variable as X\n",
    "X = raw_data_1.drop('win_loss', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659      win\n",
       "1580    loss\n",
       "2042     win\n",
       "1227    loss\n",
       "1314    loss\n",
       "Name: win_loss, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define target variable as y\n",
    "y = raw_data_1['win_loss']\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2259\n",
      "Test size: 184\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.075, random_state=33, stratify=y)\n",
    "\n",
    "print(f'Train size: {X_train.shape[0]}')\n",
    "print(f'Test size: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.III. Handling empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntryPrice     0\n",
       "long_short     0\n",
       "entry_month    0\n",
       "entry_date     0\n",
       "entry_day      0\n",
       "entry_hour     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum null value\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.IV. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns   :  ['EntryPrice', 'entry_month', 'entry_date', 'entry_day', 'entry_hour']\n",
      "Categorical Columns :  ['long_short']\n"
     ]
    }
   ],
   "source": [
    "# Get Numerical Columns and Categorical Columns\n",
    "\n",
    "num_columns = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print('Numerical Columns   : ', num_columns)\n",
    "print('Categorical Columns : ', cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaler using min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fir and transform scaling\n",
    "X_train_scaled = scaler.fit_transform(X_train_2[num_columns])\n",
    "X_test_scaled = scaler.transform(X_test[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define scaler using standard scaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # fir and transform scaling\n",
    "# X_train_scaled = scaler.fit_transform(X_train_2[num_columns])\n",
    "# X_test_scaled = scaler.transform(X_test[num_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.V. Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Encoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# fit and transform scaling\n",
    "X_train_encoded = encoder.fit_transform(X_train_2[cat_columns])\n",
    "X_test_encoded = encoder.transform(X_test[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize new encoded data\n",
    "X_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat encoded and scaled training dataset\n",
    "X_train_fin = np.concatenate((X_train_encoded, X_train_scaled), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat encoded and scaled test dataset\n",
    "X_test_fin = np.concatenate((X_test_encoded, X_test_scaled), axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Model Productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = RandomForestClassifier(max_depth=650, n_estimators=870)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=650, n_estimators=870)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=650, n_estimators=870)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=650, n_estimators=870)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X_train_fin, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the dataset\n",
    "y_train_pred=model.predict(X_train_fin)\n",
    "y_test_pred=model.predict(X_test_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       0.92      0.95      0.93      1393\n",
      "         win       0.91      0.86      0.88       866\n",
      "\n",
      "    accuracy                           0.91      2259\n",
      "   macro avg       0.91      0.90      0.91      2259\n",
      "weighted avg       0.91      0.91      0.91      2259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate training model\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       0.73      0.86      0.79       114\n",
      "         win       0.68      0.49      0.57        70\n",
      "\n",
      "    accuracy                           0.72       184\n",
      "   macro avg       0.71      0.67      0.68       184\n",
      "weighted avg       0.71      0.72      0.71       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test model\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.I. Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file_1:\n",
    "  joblib.dump(model, file_1)\n",
    "\n",
    "with open('model_scaler.pkl', 'wb') as file_2:\n",
    "  joblib.dump(scaler, file_2)\n",
    "\n",
    "with open('model_encoder.pkl', 'wb') as file_3:\n",
    "  joblib.dump(encoder, file_3)\n",
    "\n",
    "with open('list_num.txt', 'w') as file_4:\n",
    "  json.dump(num_columns, file_4)\n",
    "\n",
    "with open('list_cat.txt', 'w') as file_5:\n",
    "  json.dump(cat_columns, file_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.II. Preprocessing inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryPrice</th>\n",
       "      <th>win_loss</th>\n",
       "      <th>long_short</th>\n",
       "      <th>entry_month</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_day</th>\n",
       "      <th>entry_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>1.10287</td>\n",
       "      <td>loss</td>\n",
       "      <td>long</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>1.12722</td>\n",
       "      <td>win</td>\n",
       "      <td>short</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1.29932</td>\n",
       "      <td>win</td>\n",
       "      <td>long</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EntryPrice win_loss long_short  entry_month  entry_date  entry_day  \\\n",
       "2076     1.10287     loss       long            9           4          2   \n",
       "2187     1.12722      win      short            6          16          1   \n",
       "1057     1.29932      win       long            6           2          6   \n",
       "\n",
       "      entry_hour  \n",
       "2076           8  \n",
       "2187          12  \n",
       "1057          12  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize inference dataset\n",
    "data_inf.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting index\n",
    "data_inf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and scaling the dataset\n",
    "inf_scaled = scaler.transform(data_inf[num_columns])\n",
    "inf_encoded = encoder.transform(data_inf[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.56578567, 0.36363636, 0.23333333,\n",
       "        0.16666667, 0.4       ],\n",
       "       [1.        , 0.        , 0.03219683, 0.09090909, 0.73333333,\n",
       "        0.5       , 1.        ],\n",
       "       [0.        , 1.        , 0.07057633, 0.18181818, 0.93333333,\n",
       "        0.33333333, 0.2       ],\n",
       "       [1.        , 0.        , 0.54082002, 0.63636364, 0.33333333,\n",
       "        0.        , 0.4       ],\n",
       "       [0.        , 1.        , 0.50715887, 1.        , 0.66666667,\n",
       "        0.66666667, 0.        ],\n",
       "       [0.        , 1.        , 0.25616458, 0.90909091, 0.3       ,\n",
       "        0.16666667, 0.4       ],\n",
       "       [0.        , 1.        , 0.24463085, 0.63636364, 0.46666667,\n",
       "        0.16666667, 0.2       ],\n",
       "       [1.        , 0.        , 0.18226191, 0.90909091, 0.7       ,\n",
       "        0.5       , 0.        ],\n",
       "       [0.        , 1.        , 0.16224962, 0.72727273, 0.5       ,\n",
       "        0.33333333, 0.4       ],\n",
       "       [1.        , 0.        , 0.17325909, 1.        , 0.53333333,\n",
       "        0.        , 0.6       ],\n",
       "       [0.        , 1.        , 0.78266686, 0.81818182, 0.96666667,\n",
       "        0.66666667, 0.6       ],\n",
       "       [0.        , 1.        , 0.15697086, 0.45454545, 0.73333333,\n",
       "        0.16666667, 0.        ],\n",
       "       [1.        , 0.        , 0.27653843, 0.45454545, 0.76666667,\n",
       "        0.5       , 0.4       ],\n",
       "       [1.        , 0.        , 0.72342541, 1.        , 0.76666667,\n",
       "        0.        , 0.6       ],\n",
       "       [0.        , 1.        , 0.48105431, 0.27272727, 0.56666667,\n",
       "        0.5       , 0.8       ],\n",
       "       [1.        , 0.        , 0.46165666, 0.72727273, 0.5       ,\n",
       "        0.16666667, 0.8       ],\n",
       "       [1.        , 0.        , 0.04774387, 0.27272727, 0.43333333,\n",
       "        0.16666667, 0.6       ],\n",
       "       [0.        , 1.        , 0.24175645, 0.90909091, 0.63333333,\n",
       "        0.        , 0.8       ],\n",
       "       [1.        , 0.        , 0.57480657, 0.81818182, 0.2       ,\n",
       "        0.        , 0.2       ],\n",
       "       [1.        , 0.        , 0.14364741, 0.36363636, 0.26666667,\n",
       "        0.5       , 0.2       ],\n",
       "       [1.        , 0.        , 0.76457083, 0.45454545, 0.23333333,\n",
       "        0.33333333, 1.        ],\n",
       "       [0.        , 1.        , 0.18209921, 0.54545455, 0.4       ,\n",
       "        0.5       , 0.4       ],\n",
       "       [0.        , 1.        , 0.53489045, 0.81818182, 0.13333333,\n",
       "        0.33333333, 0.6       ],\n",
       "       [1.        , 0.        , 0.58709957, 0.09090909, 0.66666667,\n",
       "        1.        , 1.        ],\n",
       "       [1.        , 0.        , 0.15284909, 0.72727273, 0.46666667,\n",
       "        0.5       , 0.4       ],\n",
       "       [0.        , 1.        , 0.65418685, 0.54545455, 0.03333333,\n",
       "        0.5       , 0.4       ],\n",
       "       [0.        , 1.        , 0.15057126, 0.72727273, 0.03333333,\n",
       "        0.33333333, 0.4       ],\n",
       "       [1.        , 0.        , 0.57995878, 0.45454545, 0.76666667,\n",
       "        0.16666667, 0.8       ],\n",
       "       [0.        , 1.        , 0.15830863, 0.45454545, 0.5       ,\n",
       "        0.16666667, 0.6       ],\n",
       "       [1.        , 0.        , 0.72604671, 0.63636364, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.60382168, 0.18181818, 0.06666667,\n",
       "        0.        , 0.8       ],\n",
       "       [0.        , 1.        , 0.14794996, 0.72727273, 0.4       ,\n",
       "        0.16666667, 0.8       ],\n",
       "       [0.        , 1.        , 0.13986912, 0.        , 0.03333333,\n",
       "        0.5       , 0.6       ],\n",
       "       [0.        , 1.        , 0.47143684, 0.27272727, 0.83333333,\n",
       "        0.66666667, 0.2       ],\n",
       "       [1.        , 0.        , 0.44598308, 0.72727273, 0.73333333,\n",
       "        0.16666667, 0.4       ],\n",
       "       [1.        , 0.        , 0.36188445, 1.        , 0.33333333,\n",
       "        0.5       , 1.        ],\n",
       "       [1.        , 0.        , 0.37482826, 0.90909091, 0.86666667,\n",
       "        0.5       , 0.6       ],\n",
       "       [0.        , 1.        , 0.35637067, 0.27272727, 0.53333333,\n",
       "        0.16666667, 0.6       ],\n",
       "       [1.        , 0.        , 0.92794128, 0.36363636, 0.16666667,\n",
       "        0.16666667, 0.6       ],\n",
       "       [0.        , 1.        , 0.25001808, 0.63636364, 0.66666667,\n",
       "        0.66666667, 0.4       ],\n",
       "       [0.        , 1.        , 0.34941066, 0.27272727, 0.36666667,\n",
       "        0.5       , 1.        ],\n",
       "       [1.        , 0.        , 0.22333502, 0.72727273, 0.36666667,\n",
       "        0.33333333, 0.6       ],\n",
       "       [0.        , 1.        , 0.76486008, 0.72727273, 0.9       ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.60544869, 0.09090909, 0.66666667,\n",
       "        0.66666667, 0.4       ],\n",
       "       [0.        , 1.        , 0.34462   , 0.18181818, 0.46666667,\n",
       "        0.5       , 0.6       ],\n",
       "       [1.        , 0.        , 0.70516668, 0.72727273, 0.16666667,\n",
       "        1.        , 0.6       ],\n",
       "       [0.        , 1.        , 0.67927905, 0.45454545, 0.06666667,\n",
       "        0.33333333, 0.8       ],\n",
       "       [0.        , 1.        , 0.24698098, 0.63636364, 0.7       ,\n",
       "        0.16666667, 0.4       ],\n",
       "       [1.        , 0.        , 0.71688119, 0.54545455, 0.93333333,\n",
       "        0.66666667, 0.6       ],\n",
       "       [0.        , 1.        , 0.59877793, 0.36363636, 0.6       ,\n",
       "        0.        , 0.8       ],\n",
       "       [0.        , 1.        , 0.15977294, 1.        , 0.16666667,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.25066888, 0.63636364, 0.43333333,\n",
       "        0.        , 0.6       ],\n",
       "       [0.        , 1.        , 0.13034203, 0.45454545, 0.13333333,\n",
       "        0.66666667, 0.6       ],\n",
       "       [1.        , 0.        , 0.17457878, 0.        , 0.9       ,\n",
       "        0.33333333, 0.2       ],\n",
       "       [1.        , 0.        , 0.55549931, 1.        , 0.13333333,\n",
       "        0.        , 0.4       ],\n",
       "       [0.        , 1.        , 0.19117434, 0.        , 0.46666667,\n",
       "        0.16666667, 0.4       ],\n",
       "       [0.        , 1.        , 0.15977294, 1.        , 0.16666667,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.34948297, 0.18181818, 0.4       ,\n",
       "        0.16666667, 0.2       ],\n",
       "       [0.        , 1.        , 0.77247089, 0.90909091, 0.63333333,\n",
       "        0.16666667, 0.        ],\n",
       "       [0.        , 1.        , 0.63536771, 0.54545455, 0.2       ,\n",
       "        0.16666667, 0.8       ],\n",
       "       [1.        , 0.        , 0.11428881, 0.72727273, 0.1       ,\n",
       "        0.33333333, 0.4       ],\n",
       "       [1.        , 0.        , 0.1604599 , 0.27272727, 0.36666667,\n",
       "        0.66666667, 0.        ],\n",
       "       [1.        , 0.        , 0.46943018, 0.45454545, 0.03333333,\n",
       "        1.        , 0.6       ],\n",
       "       [1.        , 0.        , 0.2431123 , 0.81818182, 0.26666667,\n",
       "        0.        , 0.8       ],\n",
       "       [0.        , 1.        , 0.53203413, 0.63636364, 0.9       ,\n",
       "        0.33333333, 0.4       ],\n",
       "       [0.        , 1.        , 0.12439439, 1.        , 0.83333333,\n",
       "        0.5       , 0.2       ],\n",
       "       [0.        , 1.        , 0.63408417, 0.45454545, 0.8       ,\n",
       "        0.5       , 0.4       ],\n",
       "       [1.        , 0.        , 0.22355196, 0.45454545, 0.93333333,\n",
       "        0.66666667, 0.        ],\n",
       "       [1.        , 0.        , 0.554035  , 0.27272727, 0.13333333,\n",
       "        0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.15279485, 0.27272727, 0.06666667,\n",
       "        0.33333333, 0.8       ],\n",
       "       [1.        , 0.        , 0.11909755, 0.72727273, 0.6       ,\n",
       "        0.5       , 0.4       ],\n",
       "       [0.        , 1.        , 0.36571697, 0.36363636, 0.63333333,\n",
       "        0.5       , 0.        ],\n",
       "       [0.        , 1.        , 0.33319474, 0.        , 0.06666667,\n",
       "        1.        , 0.6       ],\n",
       "       [0.        , 1.        , 0.33603297, 0.36363636, 1.        ,\n",
       "        0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.57307108, 0.45454545, 0.5       ,\n",
       "        0.        , 0.6       ],\n",
       "       [1.        , 0.        , 0.29734616, 0.27272727, 0.6       ,\n",
       "        0.        , 0.2       ],\n",
       "       [0.        , 1.        , 0.63865789, 0.81818182, 0.7       ,\n",
       "        0.66666667, 0.        ],\n",
       "       [1.        , 0.        , 0.64182153, 0.45454545, 0.66666667,\n",
       "        1.        , 0.6       ],\n",
       "       [0.        , 1.        , 0.59438499, 0.18181818, 0.56666667,\n",
       "        0.5       , 0.2       ],\n",
       "       [1.        , 0.        , 0.46089739, 0.09090909, 0.33333333,\n",
       "        0.33333333, 0.2       ],\n",
       "       [0.        , 1.        , 0.46471184, 0.81818182, 0.23333333,\n",
       "        0.        , 0.4       ],\n",
       "       [0.        , 1.        , 0.2422084 , 0.90909091, 0.63333333,\n",
       "        0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.69477186, 0.63636364, 0.6       ,\n",
       "        0.33333333, 0.6       ],\n",
       "       [1.        , 0.        , 0.13609082, 0.63636364, 0.26666667,\n",
       "        0.16666667, 1.        ],\n",
       "       [1.        , 0.        , 0.40941138, 0.81818182, 0.4       ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.68623906, 1.        , 0.96666667,\n",
       "        0.16666667, 0.2       ],\n",
       "       [1.        , 0.        , 0.92139706, 0.36363636, 0.16666667,\n",
       "        0.16666667, 0.        ],\n",
       "       [1.        , 0.        , 0.14690144, 0.72727273, 0.4       ,\n",
       "        0.16666667, 0.6       ],\n",
       "       [0.        , 1.        , 0.59986261, 0.09090909, 0.63333333,\n",
       "        0.5       , 0.4       ],\n",
       "       [1.        , 0.        , 0.16447321, 0.27272727, 0.53333333,\n",
       "        0.33333333, 0.        ],\n",
       "       [1.        , 0.        , 0.2653301 , 0.54545455, 0.26666667,\n",
       "        0.66666667, 0.4       ],\n",
       "       [0.        , 1.        , 0.11119748, 0.36363636, 0.7       ,\n",
       "        0.66666667, 0.6       ],\n",
       "       [1.        , 0.        , 0.57889218, 0.09090909, 0.73333333,\n",
       "        0.16666667, 0.2       ],\n",
       "       [1.        , 0.        , 0.0831405 , 0.09090909, 0.66666667,\n",
       "        0.66666667, 0.6       ],\n",
       "       [0.        , 1.        , 0.14899848, 0.72727273, 0.86666667,\n",
       "        0.16666667, 0.6       ],\n",
       "       [0.        , 1.        , 0.47897534, 1.        , 0.7       ,\n",
       "        0.5       , 0.4       ],\n",
       "       [1.        , 0.        , 0.46735122, 0.        , 0.06666667,\n",
       "        0.16666667, 0.        ],\n",
       "       [0.        , 1.        , 0.66257502, 0.54545455, 0.        ,\n",
       "        0.33333333, 0.        ],\n",
       "       [0.        , 1.        , 0.21250633, 0.81818182, 0.33333333,\n",
       "        0.        , 0.4       ],\n",
       "       [1.        , 0.        , 0.41798033, 0.81818182, 0.86666667,\n",
       "        0.        , 0.6       ],\n",
       "       [0.        , 1.        , 0.17011353, 0.63636364, 0.83333333,\n",
       "        0.33333333, 0.8       ],\n",
       "       [1.        , 0.        , 0.07786174, 0.        , 0.83333333,\n",
       "        0.16666667, 0.2       ],\n",
       "       [1.        , 0.        , 0.08089884, 0.        , 0.2       ,\n",
       "        0.5       , 0.4       ],\n",
       "       [0.        , 1.        , 0.67839323, 0.72727273, 0.5       ,\n",
       "        0.16666667, 0.6       ],\n",
       "       [1.        , 0.        , 0.54300745, 1.        , 0.2       ,\n",
       "        0.33333333, 1.        ],\n",
       "       [0.        , 1.        , 0.68473859, 0.81818182, 0.53333333,\n",
       "        0.33333333, 0.        ],\n",
       "       [0.        , 1.        , 0.30188372, 0.27272727, 0.9       ,\n",
       "        0.33333333, 0.2       ],\n",
       "       [0.        , 1.        , 0.62848001, 0.18181818, 0.23333333,\n",
       "        0.16666667, 0.4       ],\n",
       "       [1.        , 0.        , 0.67748933, 0.54545455, 0.4       ,\n",
       "        0.33333333, 0.6       ],\n",
       "       [1.        , 0.        , 0.68584135, 0.54545455, 0.6       ,\n",
       "        0.16666667, 0.4       ],\n",
       "       [1.        , 0.        , 0.58764191, 0.72727273, 0.86666667,\n",
       "        0.16666667, 0.6       ],\n",
       "       [1.        , 0.        , 0.16215923, 0.90909091, 0.83333333,\n",
       "        0.66666667, 0.4       ],\n",
       "       [0.        , 1.        , 0.6247921 , 0.36363636, 0.23333333,\n",
       "        0.5       , 0.6       ],\n",
       "       [1.        , 0.        , 0.54300745, 1.        , 0.2       ,\n",
       "        0.33333333, 1.        ],\n",
       "       [1.        , 0.        , 0.48103623, 0.18181818, 0.16666667,\n",
       "        0.33333333, 0.        ],\n",
       "       [1.        , 0.        , 0.22190686, 0.72727273, 0.13333333,\n",
       "        0.33333333, 0.6       ],\n",
       "       [0.        , 1.        , 0.55492082, 0.18181818, 0.8       ,\n",
       "        0.33333333, 0.        ],\n",
       "       [0.        , 1.        , 0.67927905, 0.45454545, 0.06666667,\n",
       "        0.33333333, 0.8       ],\n",
       "       [0.        , 1.        , 0.12030877, 0.90909091, 0.66666667,\n",
       "        0.5       , 0.8       ],\n",
       "       [1.        , 0.        , 0.22369658, 0.45454545, 0.86666667,\n",
       "        0.33333333, 0.2       ],\n",
       "       [0.        , 1.        , 0.13431918, 0.        , 0.53333333,\n",
       "        0.66666667, 0.        ],\n",
       "       [0.        , 1.        , 0.13612698, 0.45454545, 0.03333333,\n",
       "        0.5       , 0.6       ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat encoded and scaled dataset\n",
    "X_inf = np.concatenate((inf_encoded, inf_scaled), axis=1 )\n",
    "X_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['win', 'win', 'win', 'loss', 'loss', 'win', 'loss', 'loss', 'loss',\n",
       "       'win', 'loss', 'win', 'loss', 'win', 'loss', 'loss', 'loss',\n",
       "       'loss', 'loss', 'win', 'loss', 'loss', 'loss', 'loss', 'loss',\n",
       "       'win', 'win', 'win', 'win', 'loss', 'loss', 'loss', 'loss', 'win',\n",
       "       'loss', 'loss', 'loss', 'win', 'loss', 'loss', 'win', 'win',\n",
       "       'loss', 'loss', 'loss', 'win', 'loss', 'loss', 'loss', 'win',\n",
       "       'loss', 'loss', 'loss', 'loss', 'loss', 'win', 'loss', 'loss',\n",
       "       'win', 'loss', 'loss', 'loss', 'win', 'win', 'win', 'loss', 'loss',\n",
       "       'win', 'loss', 'win', 'loss', 'win', 'win', 'win', 'win', 'loss',\n",
       "       'win', 'win', 'win', 'loss', 'win', 'loss', 'win', 'win', 'loss',\n",
       "       'win', 'loss', 'win', 'loss', 'loss', 'loss', 'loss', 'loss',\n",
       "       'loss', 'loss', 'loss', 'loss', 'win', 'loss', 'loss', 'win',\n",
       "       'win', 'win', 'loss', 'loss', 'loss', 'loss', 'loss', 'loss',\n",
       "       'win', 'loss', 'win', 'win', 'loss', 'loss', 'loss', 'loss',\n",
       "       'loss', 'win', 'win', 'win', 'loss'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the dataset\n",
    "inf_pred = model.predict(X_inf)\n",
    "inf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       0.87      0.96      0.91        68\n",
      "         win       0.94      0.81      0.87        54\n",
      "\n",
      "    accuracy                           0.89       122\n",
      "   macro avg       0.90      0.89      0.89       122\n",
      "weighted avg       0.90      0.89      0.89       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test model\n",
    "print(classification_report(data_inf['win_loss'],inf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9361702127659575\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test model\n",
    "print(precision_score(data_inf['win_loss'], inf_pred, pos_label='win'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6fdc46d709f94a4dde9dbbe3af85312113520ec750b767d8430be26c137ce87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
